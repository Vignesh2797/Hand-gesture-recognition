{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import os \n",
    "from PIL import Image \n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras.models import Sequential,Input,Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg \n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score, cohen_kappa_score\n",
    "print(\"Setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hand_gestures_dict = dict()\n",
    "reverse_hand_gestures_dict = dict()\n",
    "count = 0\n",
    "for j in os.listdir('D://Dissertation/dataset/hand_gestures/leapGestRecog/00'):\n",
    "    hand_gestures_dict[j] = count\n",
    "    reverse_hand_gestures_dict[count] = j\n",
    "    count+= 1\n",
    "print(hand_gestures_dict)\n",
    "print(reverse_hand_gestures_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "target = []\n",
    "imagesCount = 0 \n",
    "for i in range(0, 10):\n",
    "    for j in os.listdir('D://Dissertation/dataset/hand_gestures/leapGestRecog/0' + str(i) + '/'):\n",
    "        count = 0\n",
    "        for k in os.listdir('D://Dissertation/dataset/hand_gestures/leapGestRecog/0' + \n",
    "                                str(i) + '/' + j + '/'):\n",
    "            image = Image.open('D://Dissertation/dataset/hand_gestures/leapGestRecog/0' + \n",
    "                                 str(i) + '/' + j + '/' + k)\n",
    "            resized_image = image.resize((320, 120))\n",
    "            gray_image = resized_image.convert('L')\n",
    "            arr = np.array(gray_image)\n",
    "            data.append(arr) \n",
    "            count += 1\n",
    "        y_values = np.full((count, 1), hand_gestures_dict[j]) \n",
    "        target.append(y_values)\n",
    "        imagesCount += count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.unique(target)\n",
    "nClasses = len(classes)\n",
    "print('Total number of outputs : ', nClasses)\n",
    "print('Output classes : ', classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data, dtype=\"float32\")\n",
    "target = np.array(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cnn = data.copy()\n",
    "data_ml = data.copy()\n",
    "target_cnn = target.copy()\n",
    "target_ml = target.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cnn = data_cnn.reshape((imagesCount,120,320,1))\n",
    "data_cnn /= 255\n",
    "target_cnn = target_cnn.reshape(imagesCount, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ml = np.reshape(data_ml, (data_ml.shape[0], -1))\n",
    "data_ml /= 255\n",
    "target_ml = target_ml.reshape(imagesCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,x_further,y_train,y_further = train_test_split(data_ml,target_ml,test_size = 0.3)\n",
    "X_validate,X_test,y_validate,y_test = train_test_split(x_further,y_further,test_size = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_validate = scaler.transform(X_validate)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=0.95)\n",
    "\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_validate = pca.transform(X_validate)\n",
    "X_test = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier(max_depth=10)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "y_pred_clf = clf.predict(X_test)\n",
    "y_train_score_clf = clf.predict(X_train)\n",
    "y_val_score_clf = clf.predict(X_validate)\n",
    "print(\"Training Accuracy\", accuracy_score(y_train, y_train_score_clf, normalize= True, sample_weight=None))\n",
    "print(\"Validation Accuracy\", accuracy_score(y_validate, y_val_score_clf, normalize= True, sample_weight=None))\n",
    "print(\"Test Accuracy\", accuracy_score(y_test, y_pred_clf, normalize= True, sample_weight=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(recall_score(y_test, y_pred_clf, average=\"micro\"))\n",
    "\n",
    "print(precision_score( y_test, y_pred_clf, average=\"micro\"))\n",
    "\n",
    "print(f1_score(y_test, y_pred_clf, average=\"micro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rft = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=0)\n",
    "clf_rft = clf_rft.fit(X_train, y_train)\n",
    "y_pred_rft = clf_rft.predict(X_test)\n",
    "y_train_score_rft = clf_rft.predict(X_train)\n",
    "y_val_score_rft = clf_rft.predict(X_validate)\n",
    "print(\"Training Accuracy\", accuracy_score(y_train, y_train_score_rft, normalize= True, sample_weight=None))\n",
    "print(\"Validation Accuracy\", accuracy_score(y_validate, y_val_score_rft, normalize= True, sample_weight=None))\n",
    "print(\"Test Accuracy\", accuracy_score(y_test, y_pred_rft, normalize= True, sample_weight=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(recall_score(y_test, y_pred_rft, average=\"micro\"))\n",
    "\n",
    "print(precision_score( y_test, y_pred_rft, average=\"micro\"))\n",
    "\n",
    "print(f1_score(y_test, y_pred_rft, average=\"micro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=11)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "y_train_score_knn = knn.predict(X_train)\n",
    "y_val_score_knn = knn.predict(X_validate)\n",
    "print(\"Training Accuracy\", accuracy_score(y_train, y_train_score_knn, normalize= True, sample_weight=None))\n",
    "print(\"Validation Accuracy\", accuracy_score(y_validate, y_val_score_knn, normalize= True, sample_weight=None))\n",
    "print(\"Test Accuracy\", accuracy_score(y_test, y_pred_knn, normalize= True, sample_weight=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(recall_score(y_test, y_pred_knn, average=\"micro\"))\n",
    "\n",
    "print(precision_score( y_test, y_pred_knn, average=\"micro\"))\n",
    "\n",
    "print(f1_score(y_test, y_pred_knn, average=\"micro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = svm.SVC(kernel=\"rbf\")\n",
    "svc.fit(X_train, y_train)\n",
    "y_pred_svm = svc.predict(X_test)\n",
    "y_train_score_svm = svc.predict(X_train)\n",
    "y_val_score_svm = svc.predict(X_validate)\n",
    "print(\"Training Accuracy\", accuracy_score(y_train, y_train_score_svm, normalize= True, sample_weight=None))\n",
    "print(\"Validation Accuracy\", accuracy_score(y_validate, y_val_score_svm, normalize= True, sample_weight=None))\n",
    "print(\"Test Accuracy\", accuracy_score(y_test, y_pred_svm, normalize= True, sample_weight=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(recall_score(y_test, y_pred_svm, average=\"micro\"))\n",
    "\n",
    "print(precision_score( y_test, y_pred_svm, average=\"micro\"))\n",
    "\n",
    "print(f1_score(y_test, y_pred_svm, average=\"micro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB = GaussianNB()\n",
    "NB.fit(X_train, y_train)\n",
    "y_pred_nb = NB.predict(X_test)\n",
    "y_train_score_nb = NB.predict(X_train)\n",
    "y_val_score_nb = NB.predict(X_validate)\n",
    "print(\"Training Accuracy\", accuracy_score(y_train, y_train_score_nb, normalize= True, sample_weight=None))\n",
    "print(\"Validation Accuracy\", accuracy_score(y_validate, y_val_score_nb, normalize= True, sample_weight=None))\n",
    "print(\"Test Accuracy\", accuracy_score(y_test, y_pred_nb, normalize= True, sample_weight=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(recall_score(y_test, y_pred_nb, average=\"micro\"))\n",
    "\n",
    "print(precision_score( y_test, y_pred_nb, average=\"micro\"))\n",
    "\n",
    "print(f1_score(y_test, y_pred_nb, average=\"micro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,x_further,y_train,y_further = train_test_split(data_cnn,target_cnn,test_size = 0.3)\n",
    "X_validate,X_test,y_validate,test_y = train_test_split(x_further,y_further,test_size = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = tf.keras.utils.to_categorical(y_train)\n",
    "y_validate = tf.keras.utils.to_categorical(y_validate)\n",
    "test_y = tf.keras.utils.to_categorical(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training data shape : ', X_train.shape, y_train.shape)\n",
    "\n",
    "print('Validation data shape : ', X_validate.shape, y_validate.shape)\n",
    "\n",
    "print('Testing data shape : ', X_test.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(5, 5),activation='linear',input_shape=(120,320,1),padding='same'))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling2D((2, 2),padding='same'))\n",
    "model.add(Conv2D(64, (3, 3), activation='linear',padding='same'))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "model.add(Conv2D(128, (3, 3), activation='linear',padding='same'))\n",
    "model.add(LeakyReLU(alpha=0.1))                  \n",
    "model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))                \n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='linear'))\n",
    "model.add(LeakyReLU(alpha=0.1))                  \n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='Adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = model.fit(X_train, y_train, epochs=5, batch_size=64, verbose=1, validation_data=(X_validate, y_validate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = trained_model.history['accuracy']\n",
    "val_loss = trained_model.history['val_accuracy']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, color='red', label='Training accuracy')\n",
    "plt.plot(epochs, val_loss, color='green', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = trained_model.history['loss']\n",
    "val_loss = trained_model.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, color='red', label='Training loss')\n",
    "plt.plot(epochs, val_loss, color='green', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eval = model.evaluate(X_test, test_y, verbose=0)\n",
    "\n",
    "print('Test loss:', test_eval[0])\n",
    "print('Test accuracy:', test_eval[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_classes = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_classes = np.argmax(np.round(predicted_classes), axis=1)\n",
    "\n",
    "test_y = np.argmax(np.round(test_y), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(test_y, predicted_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_pred_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "cm = confusion_matrix(test_y, predicted_classes)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "\n",
    "\n",
    "\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred_svm)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "\n",
    "\n",
    "\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred_rft)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "\n",
    "\n",
    "\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred_knn)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "\n",
    "\n",
    "\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred_clf)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "\n",
    "\n",
    "\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred_nb)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "\n",
    "\n",
    "\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_combine = {'Model':  ['CNN', 'Naive Bayes','Random Forest','SVM','KNN', 'Decision Tree'],\n",
    "\n",
    "'Train_accuracy': [1.0, 0.53, 0.99, 0.99, 0.99, 0.97],\n",
    "               \n",
    "'Validation_accuracy': [1.0, 0.51, 0.99, 0.99, 0.99, 0.95],\n",
    "               \n",
    "'Test_accuracy': [1.0, 0.51, 0.99, 0.99, 0.99, 0.90]\n",
    "              }\n",
    "               \n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "fig = go.Figure(data=[\n",
    "    go.Bar(name='train set', x=acc_combine['Model'], y=acc_combine['Train_accuracy'],text=np.round(acc_combine['Train_accuracy'],2),textposition='outside'),\n",
    "    go.Bar(name='validation set', x=acc_combine['Model'], y=acc_combine['Validation_accuracy'],text=np.round(acc_combine['Validation_accuracy'],2),textposition='outside'),\n",
    "    go.Bar(name='test set', x=acc_combine['Model'], y=acc_combine['Test_accuracy'],text=np.round(acc_combine['Test_accuracy'],2),textposition='outside')\n",
    "])\n",
    "\n",
    "fig.update_layout(barmode='group',title_text='Accuracy Comparison On Different Models',yaxis=dict(\n",
    "        title='Accuracy'))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
